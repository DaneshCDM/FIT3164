{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGDQO_nj8ru3",
        "outputId": "4ee2f481-3e86-4ee6-8f15-58ffa08e196a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ],
      "id": "RGDQO_nj8ru3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g-2Nmif78sM-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "# Assign API key\n",
        "openai.api_key = \"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\""
      ],
      "id": "g-2Nmif78sM-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QuKyTCVY8sQB"
      },
      "outputs": [],
      "source": [
        "def chatWithGPT(prompt):\n",
        "  completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "  {\"role\": \"user\", \"content\": prompt}\n",
        "  ]\n",
        "  )\n",
        "  #return print(completion.choices[0].message.content)\n",
        "  return completion.choices[0].message.content"
      ],
      "id": "QuKyTCVY8sQB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "hEch7yEdgJUb",
        "outputId": "8343788d-1c1a-4f01-a4bc-2ef8b326372e"
      },
      "outputs": [
        {
          "ename": "APIError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0b2270026631>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'a dog is flying in the sky'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0moriginal_metaphor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-0b2270026631>\u001b[0m in \u001b[0;36moriginal_metaphor\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moriginal_metaphor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfinal_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Convert this sentence to metaphor sentence: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   completion = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   messages=[\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/chat_completion.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTryAgain\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_resources/abstract/engine_api_resource.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    153\u001b[0m         )\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         response, _, api_key = requestor.request(\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mrequest_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         )\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpret_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgot_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             return (\n\u001b[0;32m--> 710\u001b[0;31m                 self._interpret_response_line(\n\u001b[0m\u001b[1;32m    711\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/api_requestor.py\u001b[0m in \u001b[0;36m_interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mstream_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"error\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream_error\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mrcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 775\u001b[0;31m             raise self.handle_error_response(\n\u001b[0m\u001b[1;32m    776\u001b[0m                 \u001b[0mrbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             )\n",
            "\u001b[0;31mAPIError\u001b[0m: Internal server error {\n    \"error\": {\n        \"message\": \"Internal server error\",\n        \"type\": \"auth_subrequest_error\",\n        \"param\": null,\n        \"code\": \"internal_error\"\n    }\n}\n 500 {'error': {'message': 'Internal server error', 'type': 'auth_subrequest_error', 'param': None, 'code': 'internal_error'}} {'Date': 'Fri, 20 Oct 2023 00:28:53 GMT', 'Content-Type': 'application/json; charset=utf-8', 'Content-Length': '166', 'Connection': 'keep-alive', 'vary': 'Origin', 'x-request-id': '0eb5daf1d8d94c43e2cdd5c4b92a7379', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '818d24927bd2eb73-SEA', 'alt-svc': 'h3=\":443\"; ma=86400'}"
          ]
        }
      ],
      "source": [
        "#below function can used to compare with the final output, BUT note that the outputs you run many times for a same input can have very big difference\n",
        "def original_metaphor(prompt):\n",
        "  final_prompt = \"Convert this sentence to metaphor sentence: \" + prompt\n",
        "  completion = openai.ChatCompletion.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "  {\"role\": \"user\", \"content\": final_prompt}\n",
        "  ]\n",
        "  )\n",
        "  return print(completion.choices[0].message.content)\n",
        "\n",
        "prompt = 'a dog is flying in the sky'\n",
        "original_metaphor(prompt)"
      ],
      "id": "hEch7yEdgJUb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeiqbyMTKgg3"
      },
      "source": [
        "##Generation of Dataset\n",
        "###refer to https://images.datacamp.com/image/upload/v1678453027/Marketing/Blog/ChatGPT_Cheat_Sheet.pdf data generation part (start from pg29)\n"
      ],
      "id": "MeiqbyMTKgg3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dquT8ULayGlq"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "training_data= [\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A cat rides a bicycle through a rainstorm.->\", \"completion\": \"\"\"In adversity, one must adapt to survive. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A tree dances gracefully in the moonlight.->\", \"completion\": \"\"\"Even the silent can express their beauty. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A penguin serves as a DJ at a beach party.->\", \"completion\": \"\"\"Unusual talents can make anyone shine. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A fish plays chess against a giraffe.->\", \"completion\": \"\"\"Intelligence is not bound by appearances. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A snail wins the Grand Prix in a race of cheetahs.->\", \"completion\": \"\"\"Persistence can outshine speed. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A bookshelf serenades a library with love songs.->\", \"completion\": \"\"\"Knowledge brings joy to the soul. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A cloud practices ballet in the sky.->\", \"completion\": \"\"\"Grace can be found in unexpected places. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A squirrel composes poetry with acorns.->\", \"completion\": \"\"\"Creativity knows no boundaries. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A pineapple hosts a talk show for fruit celebrities.->\", \"completion\": \"\"\"Everyone has a story to share. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A sunflower paints a masterpiece with sunlight.->\", \"completion\": \"\"\"Art can be the essence of life. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A cat reads Shakespeare to a group of mice.->\", \"completion\": \"\"\"Wisdom transcends differences. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A giraffe paints a rainbow in a desert.->\", \"completion\": \"\"\"Creativity can bring life to barren places. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A bear conducts a symphony for a forest audience.->\", \"completion\": \"\"\"Music can unite even the wildest of hearts. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A turtle wins a marathon against hares.->\", \"completion\": \"\"\"Slow and steady progress can achieve the impossible. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A crab writes poetry with seashells.->\", \"completion\": \"\"\"Beauty is where you find it. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A snowflake paints a mural on a blizzard.->\", \"completion\": \"\"\"Individuality is a work of art. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A snail invents a rocket to reach the moon.->\", \"completion\": \"\"\"Ambition transcends limitations. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A dolphin writes love letters to the moon.->\", \"completion\": \"\"\"Love can be a timeless connection. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A treehouse hosts a summit for birds.->\", \"completion\": \"\"\"Community is found in shared dreams. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A cactus plays the trumpet for a desert crowd.->\", \"completion\": \"\"\"Music can flourish in unexpected places. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A firefly conducts a light orchestra.->\", \"completion\": \"\"\"Creativity shines brightest in the dark. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A crocodile hosts a tea party for a group of flamingos.->\", \"completion\": \"\"\"Hospitality knows no boundaries. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A dragonfly writes poetry with its wings.->\", \"completion\": \"\"\"Art can take flight in the smallest of moments. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A lion teaches meditation to a group of zebras.->\", \"completion\": \"\"\"Inner peace is a universal gift. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A kangaroo teaches yoga to a group of frogs.->\", \"completion\": \"\"\"Balance is a universal lesson. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A sunflower writes poetry with its petals.->\", \"completion\": \"\"\"Art can bloom from the simplest of forms. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A rocket ship serves as a taxi for aliens.->\", \"completion\": \"\"\"Innovation knows no borders. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A snowflake hosts a winter fashion show.->\", \"completion\": \"\"\"Uniqueness is its own style. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A penguin coaches a soccer team of polar bears.->\", \"completion\": \"\"\"Dedication conquers any field. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A squirrel paints a mural on a skyscraper.->\", \"completion\": \"\"\"Vision can reach great heights. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A kid blowing with a lemon in his mouth.->\", \"completion\": \"\"\"A child's laughter carries the sweetness of a lemon breeze. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A man in front of blue light.->\", \"completion\": \"\"\"An embodiment of tranquility. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Eggs inside a small nest.->\", \"completion\": \"\"\"Life's potential, cradled in a cozy embrace. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Eggs inside a small nest.->\", \"completion\": \"\"\"Possibilities of existence, nestled in a warm and secure hug.. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Eggs inside a small nest.->\", \"completion\": \"\"\"Potential, wrapped gently in the comforting arms of existence.\n",
        " \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A small box full of different types of cutler.->\", \"completion\": \"\"\"Within a compact chest, a symphony of utensils harmonizes, each piece a note in the orchestra of dining. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A small box full of different types of cutler.->\", \"completion\": \"\"\"In a small box, kitchen tools work together like a team, each one playing its role in making a meal. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A small box full of different types of cutler.->\", \"completion\": \"\"\"Inside a little chest, kitchen utensils collaborate smoothly, just like musicians in a band, making dining a joyful experience. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A man on display.->\", \"completion\": \"\"\"A lone figure in the spotlight, the man becomes a canvas for the world's gaze. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A man on display.->\", \"completion\": \"\"\"A lone figure in the spotlight, The man transforms into a blank canvas, where the world's eyes paint their stories. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A lock with several keys.->\", \"completion\": \"\"\"A heart with numerous secrets. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A lock with several keys.->\", \"completion\": \"\"\"A heart, hiding many untold stories. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A lock with several keys.->\", \"completion\": \"\"\"A heart filled with countless mysteries. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A glass filled with water.->\", \"completion\": \"\"\"A crystal goblet cradling liquid secrets. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: An ice cream cone covered in ice with the earth melting on top->\", \"completion\": \"\"\"A frozen treat adorned with frozen layers, the world's troubles slowly dissipate. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: An ice cream cone covered in ice with the earth melting on top->\", \"completion\": \"\"\"Like an ice cream with layers of serenity, the world's problems melt away bit by bit. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: An ice cream cone covered in ice with the earth melting on top->\", \"completion\": \"\"\"With each frozen layer, this treat of tranquility gradually melts away the world's worries. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A road with an image of a car.->\", \"completion\": \"\"\"Path to self-discovery. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A road with an image of a car.->\", \"completion\": \"\"\"The journey toward understanding oneself. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A road with an image of a car.->\", \"completion\": \"\"\"The road to discovering your true self. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person holding up an light bulb.->\", \"completion\": \"\"\"Path to inspiration. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person holding up an light bulb.->\", \"completion\": \"\"\"The winding trail that leads to creative enlightenment. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person holding up an light bulb.->\", \"completion\": \"\"\"A meandering path, where each step unveils a new spark of inspiration. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person flying with balloons in the air..->\", \"completion\": \"\"\"Dreams taking flight with colorful balloons. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person flying with balloons in the air..->\", \"completion\": \"\"\"As dreams ascend like vibrant balloons, they carry us to new heights of possibility. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: The letter O made up of gears and cogwheels.->\", \"completion\": \"\"\"Precision engineering forming the core of innovation. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: The letter O made up of gears and cogwheels.->\", \"completion\": \"\"\"Like a finely crafted masterpiece, precision engineering lies at the heart of every innovative breakthrough. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: The letter O made up of gears and cogwheels.->\", \"completion\": \"\"\"In the world of innovation, precision engineering serves as the solid foundation upon which creativity builds its towering achievements. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A man with a blue shirt holding a globe.->\", \"completion\": \"\"\"Knowledge in the palm of his hand, a world at his fingertips. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A man with a blue shirt holding a globe.->\", \"completion\": \"\"\"With knowledge at his fingertips, he holds the entire world within his grasp. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person on top of the moon, with a telescope in his hands.->\", \"completion\": \"\"\"Exploration reaching new heights. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person on top of the moon, with a telescope in his hands.->\", \"completion\": \"\"\"Exploration soaring to unprecedented altitudes. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person on top of the moon, with a telescope in his hands.->\", \"completion\": \"\"\"The pursuit of discovery scaling new peaks. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A woman holding her fingerprint.->\", \"completion\": \"\"\"A glimpse into her individuality, etched in the lines of her hand. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A woman holding her fingerprint.->\", \"completion\": \"\"\"Her unique essence is like a story written in the lines of her hand, waiting to be read. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Two hands holding the earth.->\", \"completion\": \"\"\"Like protectors of a fragile treasure, we gently hold our world in our hands. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Two hands holding the earth.->\", \"completion\": \"\"\"We cradle our world together. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Two hands holding the earth.->\", \"completion\": \"\"\"United, we are the guardians cradling the Earth, nurturing its well-being and future. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Green leaves on the car..->\", \"completion\": \"\"\"Nature's touch makes the car a peaceful place. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A light bulb surrounded by many barbed.->\", \"completion\": \"\"\"Like a thorny embrace, innovation is safeguarded from harm and nurtured to grow. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A wooden man holding an axe with a blue clock in the background.->\", \"completion\": \"\"\"Time ticking away as the wooden figure wields the instrument of change. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A wooden man holding an axe with a blue clock in the background.->\", \"completion\": \"\"\"Time moves forward as a wooden figure guides the instrument of change. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A wooden man holding an axe with a blue clock in the background.->\", \"completion\": \"\"\"Like a clock in motion, time progresses while a wooden figure steers the instrument of transformation. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person dressed up like a dinosaur with a handmade mask on their head.->\", \"completion\": \"\"\"A prehistoric wanderer in a modern world. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person dressed up like a dinosaur with a handmade mask on their head.->\", \"completion\": \"\"\"A traveler from the past navigating a contemporary world. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A person dressed up like a dinosaur with a handmade mask on their head.->\", \"completion\": \"\"\"Like a relic from ancient times, he roams in our modern era, exploring a new world. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A girl being trained by an Israeli military during her training.->\", \"completion\": \"\"\"A fragile bud, forced to bloom amidst the thorns of Israeli military training. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A girl being trained by an Israeli military during her training.->\", \"completion\": \"\"\"Like a delicate bud, compelled to blossom amid the challenges of Israeli military training. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A girl being trained by an Israeli military during her training.->\", \"completion\": \"\"\"A fragile bud, finding the strength to bloom amidst the thorns of Israeli military training. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: The scale of a heart and brain.->\", \"completion\": \"\"\"Balance between emotions and intellect tips the scales of life. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: The scale of a heart and brain.->\", \"completion\": \"\"\"Life's balance hinges on the interplay between emotions and intellect. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: The scale of a heart and brain.->\", \"completion\": \"\"\"Like a delicate scale, life tilts and turns with the equilibrium of emotions and intellect. \\n\"\"\"},\n",
        "\n",
        " ]\n"
      ],
      "id": "dquT8ULayGlq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1gVl-keyNwK"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "validation_data= [\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A penguin juggles flamingos at the circus.->\", \"completion\": \"\"\"Balance in chaos creates wonder. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A koala conducts a symphony of tree leaves.->\", \"completion\": \"\"\"Harmony lies within diversity. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A butterfly sings opera to a crowd of caterpillars.->\", \"completion\": \"\"\"Transformation brings new talents. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A teapot explores the cosmos in a rocket ship.->\", \"completion\": \"\"\"Curiosity knows no bounds. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A pineapple teaches yoga to a group of pineapples.->\", \"completion\": \"\"\"Inner peace is universal. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A giraffe hosts a cooking show for short animals.->\", \"completion\": \"\"\"Expertise transcends stature. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A small tree on a rocky area.->\", \"completion\": \"\"\"Amidst the unforgiving terrain of life, a small tree stands tall, defying the odds. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A small tree on a rocky area.->\", \"completion\": \"\"\"In life's tough journey, a small tree stands strong, showing us how to overcome challenges. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A small tree on a rocky area.->\", \"completion\": \"\"\"Like a determined sapling in a rugged world, it reminds us that even small efforts can conquer life's hardships. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A clock hanging off a tree.->\", \"completion\": \"\"\"Time, like a clock hanging off a tree, remains an ever-present part of nature's grand design. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A clock hanging off a tree.->\", \"completion\": \"\"\"Time, akin to a clock on a tree, is a constant element in the grand design of nature. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A clock hanging off a tree.->\", \"completion\": \"\"\"Like a clock on a tree, time is an integral part of the natural order, always ticking forward. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A bottle with an image on it.->\", \"completion\": \"\"\"A bottle wears a story on its surface. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Watermelons with sunglasses on top.->\", \"completion\": \"\"\"\"Life's challenges are our 'sunglasses,' with watermelons on top, unexpected moments of joy. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Watermelons with sunglasses on top.->\", \"completion\": \"\"\"\"Life's challenges are like our protective shades, and every now and then, we discover unexpected moments of joy, like finding a sweet watermelon. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Watermelons with sunglasses on top.->\", \"completion\": \"\"\"\"Life's difficulties are like sunglasses that occasionally reveal delightful surprises, much like coming across a juicy watermelon on a sunny day. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A sandwich with text on the back.->\", \"completion\": \"\"\"Like a sandwich layered with hidden stories, life carries the unspoken tales on its back. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A sandwich with text on the back.->\", \"completion\": \"\"\"Life is like a sandwich with hidden stories between its layers, carrying untold tales along its journey. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A sandwich with text on the back.->\", \"completion\": \"\"\"Just like a layered sandwich, life holds unspoken stories between its layers, carrying them with grace. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: Wedding cake with a newly bride and groom.->\", \"completion\": \"\"\"The union of two souls in sweet harmony. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A light bulb surrounded by many barbed.->\", \"completion\": \"\"\"Innovation protected by a thorny embrace. \\n\"\"\"},\n",
        "\n",
        "    {\"prompt\": \"Convert this sentence to a metaphor sentence: A light bulb surrounded by many barbed.->\", \"completion\": \"\"\"Innovation, sheltered by a protective shield of thorns. \\n\"\"\"},\n",
        "\n",
        " ]\n"
      ],
      "id": "B1gVl-keyNwK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4rAsD6Meh3k"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "training_file_name= \"training_data.jsonl\"\n",
        "validation_file_name = \"validation_data.jsonl\"\n",
        "\n",
        "def prepare_data(dictionary_data, final_file_name):\n",
        "\n",
        "\twith open(final_file_name, 'w') as outfile:\n",
        "\t\tfor entry in dictionary_data:\n",
        "\t\t\tjson.dump(entry, outfile)\n",
        "\t\t\toutfile.write('\\n')\n",
        "\n",
        "prepare_data(training_data, \"training_data.jsonl\")\n",
        "prepare_data(validation_data, \"validation_data.jsonl\")"
      ],
      "id": "g4rAsD6Meh3k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FoZm-YvOy_ET"
      },
      "outputs": [],
      "source": [
        "#Below code may give some suggestion, decide whether accept or not\n",
        "!openai tools fine_tunes.prepare_data -f \"training_data.jsonl\"\n",
        "!openai tools fine_tunes.prepare_data -f \"validation_data.jsonl\""
      ],
      "id": "FoZm-YvOy_ET"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fgByq9-78seV"
      },
      "outputs": [],
      "source": [
        "#uploading the training dataset\n",
        "training_file_create=openai.File.create(\n",
        "  file=open(\"training_data_prepared.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "id": "fgByq9-78seV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8qZUTb01ZKu"
      },
      "outputs": [],
      "source": [
        "#uploading the validation dataset\n",
        "validation_file_create=openai.File.create(\n",
        "  file=open(\"validation_data_prepared.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ],
      "id": "C8qZUTb01ZKu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsQfRutc1eiD"
      },
      "outputs": [],
      "source": [
        "#Need to copy paste from the above\n",
        "training_file_id = training_file_create.id\n",
        "validation_file_id = validation_file_create.id"
      ],
      "id": "rsQfRutc1eiD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9G8j4v0J1pob"
      },
      "outputs": [],
      "source": [
        "#configuration\n",
        "create_args = {\n",
        "\t\"training_file\": training_file_id,\n",
        "\t\"validation_file\": validation_file_id,\n",
        "\t\"model\": \"davinci\",\n",
        "\t\"n_epochs\": 15,\n",
        "\t\"batch_size\": 3,\n",
        "\t\"learning_rate_multiplier\": 0.3\n",
        "}\n",
        "\n",
        "response = openai.FineTune.create(**create_args)\n",
        "job_id = response[\"id\"]\n",
        "status = response[\"status\"]\n",
        "\n",
        "#print(f'Fine-tunning model with jobID: {job_id}.')\n",
        "#print(f\"Training Response: {response}\")\n",
        "#print(f\"Training Status: {status}\")"
      ],
      "id": "9G8j4v0J1pob"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi7b45H811oT"
      },
      "outputs": [],
      "source": [
        "#run this so that you know when the fine tuning process is done and can process to next step\n",
        "import time\n",
        "\n",
        "status = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
        "if status not in [\"succeeded\", \"failed\"]:\n",
        "\tprint(f'Job not in terminal status: {status}. Waiting.')\n",
        "\twhile status not in [\"succeeded\", \"failed\"]:\n",
        "\t\ttime.sleep(2)\n",
        "\t\tstatus = openai.FineTune.retrieve(id=job_id)[\"status\"]\n",
        "\t\tprint(f'Status: {status}')\n",
        "else:\n",
        "\tprint(f'Finetune job {job_id} finished with status: {status}')\n",
        "\n",
        "print('Checking other finetune jobs in the subscription.')\n",
        "result = openai.FineTune.list()\n",
        "print(f'Found {len(result.data)} finetune jobs.')"
      ],
      "id": "wi7b45H811oT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAFtDNCH7A2d"
      },
      "outputs": [],
      "source": [
        "#if fine_tuned_model is Null\n",
        "retrieve_response = openai.FineTune.retrieve(response.id)\n",
        "fine_tuned_model = retrieve_response.fine_tuned_model\n",
        "fine_tuned_model"
      ],
      "id": "qAFtDNCH7A2d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9j22EW-NcneB"
      },
      "outputs": [],
      "source": [
        "file_path = \"/content/drive/MyDrive/fine_tuned_model.txt\"\n",
        "with open(file_path,'r') as file:\n",
        "  fine_tuned_model=file.read().strip()"
      ],
      "id": "9j22EW-NcneB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvNuwkwi2Ewj"
      },
      "outputs": [],
      "source": [
        "#testing\n",
        "new_prompt = 'A pig wears a crown'\n",
        "new_prompt = \"Convert this sentence to metaphor sentence: \" + new_prompt + \"->\"\n",
        "answer = openai.Completion.create(\n",
        "  model=fine_tuned_model,\n",
        "  prompt=new_prompt\n",
        ")\n",
        "\n",
        "print(answer['choices'][0]['text'])"
      ],
      "id": "CvNuwkwi2Ewj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6iR5ylkOXKP"
      },
      "source": [
        "###GPT function"
      ],
      "id": "-6iR5ylkOXKP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNwydG9-txwu"
      },
      "outputs": [],
      "source": [
        "def gpt(sentence):\n",
        "  flag = True\n",
        "  prompt = \"Given you the sentence below:\\n \" + sentence + \"\\n. Based on the sentence, reply me with exactly 3 lines:\\n\" + \"First line is the sentence after fixing the grammar and structure error of the given sentence. Emphasize again, just the senetence no need add any description or prefix (e.g.'the sentence after fixing:') for the first line output.\\nSecond line has only one character: if the scenario described in the sentence make sense in a realistic (NO fictional or imaginative), reply 'Y', or else 'N'.\\nThird line is the explanation for the output for second line.\"\n",
        "  reply = chatWithGPT(prompt)\n",
        "  lst = reply.split('\\n')\n",
        "  fixed_senetence = lst[0]\n",
        "  prompt1 = \"Given you the sentence below:\\n \" + sentence + \"\\n. Based on the sentence, reply me with exactly 3 lines:\\n\" + \"First line is the sentence after fixing the grammar and structure error of the given sentence. Emphasize again, just the senetence no need add any description or prefix (e.g.'the sentence after fixing:') for the first line output.\\nSecond line has only one character: do you think this sentence has a deeper(i.e. have a metaphor meaning) ? If yes, reply 'N', or else 'Y'.\\nThird line is the explanation for the output for second line.\"\n",
        "  reply1 = chatWithGPT(prompt1)\n",
        "  lst1 = reply1.split('\\n')\n",
        "  if lst[1] == 'N' or 'does not' in lst[2] or '''doesn't''' in lst[2] or 'straightforward' in lst[2] or lst[1] == 'N' or ('does not' not in lst1[2] and '''doesn't''' not in lst1[2]):\n",
        "    flag = False\n",
        "  return fixed_senetence, flag\n",
        "\n",
        "def final(sentence):\n",
        "  fixed_sentence, make_sense = gpt(sentence)\n",
        "  if make_sense:\n",
        "    print (fixed_sentence)\n",
        "    return fixed_sentence\n",
        "  else:\n",
        "    new_prompt = \"Convert this sentence to metaphor sentence: \" + fixed_sentence + \"->\"\n",
        "    answer = openai.Completion.create(\n",
        "      model=fine_tuned_model,\n",
        "      prompt=new_prompt\n",
        "    )\n",
        "    # print (\"Original sentence: \" + fixed_sentence)\n",
        "    # print(\"BUT I think it has a metaphor meaning: \" +answer['choices'][0]['text'])\n",
        "    return (\"Original sentence: \" + fixed_sentence + \"\\n\" + \"BUT I think it has a metaphor meaning: \" + answer['choices'][0]['text'])"
      ],
      "id": "JNwydG9-txwu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b949f9f"
      },
      "source": [
        "# BLIP: Inference Demo\n",
        " - [Image Captioning](#Image-Captioning)\n",
        " - [VQA](#VQA)\n",
        " - [Feature Extraction](#Feature-Extraction)\n",
        " - [Image Text Matching](#Image-Text-Matching)"
      ],
      "id": "2b949f9f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbcb066b"
      },
      "outputs": [],
      "source": [
        "# install requirements\n",
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    print('Running in Colab.')\n",
        "    !pip3 install transformers==4.15.0 timm==0.4.12 fairscale==0.4.4\n",
        "    !git clone https://github.com/salesforce/BLIP\n",
        "    %cd BLIP"
      ],
      "id": "cbcb066b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hoesp5faW-ob"
      },
      "outputs": [],
      "source": [
        "!pip install timm transformers fairscale"
      ],
      "id": "hoesp5faW-ob"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f72f4406"
      },
      "source": [
        "# Image Captioning\n",
        "Perform image captioning using finetuned BLIP model"
      ],
      "id": "f72f4406"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a811a65f"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms.functional import InterpolationMode\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def load_demo_image(image_url, image_size, device):\n",
        "    #img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg'\n",
        "    raw_image = Image.open(image_url).convert('RGB')\n",
        "\n",
        "    w,h = raw_image.size\n",
        "    display(raw_image.resize((w//5,h//5)))\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((image_size,image_size),interpolation=InterpolationMode.BICUBIC),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "        ])\n",
        "    image = transform(raw_image).unsqueeze(0).to(device)\n",
        "    return image"
      ],
      "id": "a811a65f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6835daef"
      },
      "outputs": [],
      "source": [
        "from models.blip import blip_decoder\n",
        "def original_captioning(image_url):\n",
        "  image_url = image_url\n",
        "  image_size = 384\n",
        "  image = load_demo_image(image_url, image_size=image_size, device=device)\n",
        "\n",
        "  model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth'\n",
        "\n",
        "  model = blip_decoder(pretrained=model_url, image_size=image_size, vit='base')\n",
        "  model.eval()\n",
        "  model = model.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # beam search\n",
        "      caption = model.generate(image, sample=True, num_beams=3, max_length=20, min_length=5)\n",
        "      # nucleus sampling\n",
        "      # caption = model.generate(image, sample=True, top_p=0.9, max_length=20, min_length=5)\n",
        "      return caption[0]"
      ],
      "id": "6835daef"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NojVl3wLvj-"
      },
      "source": [
        "####Cartoon: Dancing cow test"
      ],
      "id": "0NojVl3wLvj-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxPqZodf-hCi"
      },
      "outputs": [],
      "source": [
        "image_url = '/content/drive/MyDrive/test report data/dancing_cow.jpg'\n",
        "c=original_captioning(image_url)\n",
        "print(c)"
      ],
      "id": "hxPqZodf-hCi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKDpr-PLOc_R"
      },
      "source": [
        "###Final function: image_captioning"
      ],
      "id": "NKDpr-PLOc_R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-PSC0sd96aH"
      },
      "outputs": [],
      "source": [
        "def image_captioning(image_url):\n",
        "  caption = original_captioning(image_url)\n",
        "  return final(caption)\n"
      ],
      "id": "C-PSC0sd96aH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBOBv-UcPjiw"
      },
      "source": [
        "##Go to drive and generate dataset"
      ],
      "id": "TBOBv-UcPjiw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PooQPWBdtpp"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import os"
      ],
      "id": "4PooQPWBdtpp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3c0xZx8SPvb"
      },
      "outputs": [],
      "source": [
        "from models.blip import blip_decoder\n",
        "captions = []\n",
        "for img in os.listdir(\"/content/drive/MyDrive/dataset_before_b4_getting_caption\"):\n",
        "  image_url = \"/content/drive/MyDrive/dataset_before_b4_getting_caption/\"+img\n",
        "  image_size = 384\n",
        "  image = load_demo_image(image_url, image_size=image_size, device=device)\n",
        "\n",
        "  model_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_base_capfilt_large.pth'\n",
        "\n",
        "  model = blip_decoder(pretrained=model_url, image_size=image_size, vit='base')\n",
        "  model.eval()\n",
        "  model = model.to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      # beam search\n",
        "      caption = model.generate(image, sample=True, num_beams=3, max_length=20, min_length=5)\n",
        "      # nucleus sampling\n",
        "      # caption = model.generate(image, sample=True, top_p=0.9, max_length=20, min_length=5)\n",
        "      print('caption: '+caption[0])\n",
        "      captions.append(caption[0])\n",
        "with open('caption.txt','w') as fp:\n",
        "  for caption in captions:\n",
        "    fp.write(caption+'\\n')"
      ],
      "id": "r3c0xZx8SPvb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1lr3A6EdZHk"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "# Define the input and output file names\n",
        "input_file = 'caption.txt'\n",
        "output_file = 'caption.csv'\n",
        "\n",
        "# Open the text file for reading\n",
        "with open(input_file, 'r') as text_file:\n",
        "    # Read the lines from the text file\n",
        "    lines = text_file.readlines()\n",
        "\n",
        "# Split each line by comma to create a list of values\n",
        "data = [line.strip('\\n') for line in lines]\n",
        "\n",
        "# print(data)\n",
        "\n",
        "# Open the CSV file for writing\n",
        "with open(output_file, 'w', newline='') as csv_file:\n",
        "    # Create a CSV writer object\n",
        "    csv_writer = csv.writer(csv_file)\n",
        "\n",
        "    # Write the data to the CSV file\n",
        "    csv_writer.writerow(data)\n",
        "\n",
        "print(f'Conversion from {input_file} to {output_file} completed.')\n"
      ],
      "id": "l1lr3A6EdZHk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3IdkBZUkuqd"
      },
      "source": [
        "# Flask - UI Integration"
      ],
      "id": "Z3IdkBZUkuqd"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "nQQwA6z5lY8M"
      },
      "id": "nQQwA6z5lY8M",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLsTdpukkyyC",
        "outputId": "ba4667fb-e480-4f94-eb4d-603b027e3d55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_ngrok) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "# Install Module - Flask Ngrok\n",
        "!pip install flask_ngrok"
      ],
      "id": "xLsTdpukkyyC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SenCL-f9lZ2e",
        "outputId": "272eccf9-fe64-4153-b830-8821b2ee1b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok==4.1.1\n",
            "  Downloading pyngrok-4.1.1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok==4.1.1) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-4.1.1-py3-none-any.whl size=15963 sha256=ea4415bedb60d52827fad359b6d25a6d2728ffe28e52ce03feb2c7699a9f474b\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/7c/4c/632fba2ea8e88d8890102eb07bc922e1ca8fa14db5902c91a8\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-4.1.1\n"
          ]
        }
      ],
      "source": [
        "# Install Module - pyngrok 4.1.1\n",
        "!pip install pyngrok==4.1.1"
      ],
      "id": "SenCL-f9lZ2e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFpLUibVlbpr",
        "outputId": "fc66af44-13a6-47d9-f807-b46cab228152"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# Install ngrok Authentication Token\n",
        "!ngrok authtoken 2WXjyrStogpxD7k951TviEk9scR_5JNU48qJ5DLhUn3eEq14x"
      ],
      "id": "HFpLUibVlbpr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkHx2xSmli5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d18e46-911d-4407-ef4d-80c46693d17d"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://a399-104-198-96-106.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:57:56] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:57:57] \"GET /static/css/style.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:57:57] \"GET /static/js/show-caption.js HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:57:57] \"GET /static/js/upload-image.js HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:57:58] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:57:58] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:04] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:09] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:15] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:21] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:27] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:33] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:39] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:45] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:51] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:58:57] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:03] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:09] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:15] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:21] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:27] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:33] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:39] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:45] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:51] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 00:59:57] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:02] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:08] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:15] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:16] \"\u001b[36mGET /static/css/style.css HTTP/1.1\u001b[0m\" 304 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:16] \"\u001b[36mGET /static/js/show-caption.js HTTP/1.1\u001b[0m\" 304 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:16] \"\u001b[36mGET /static/js/upload-image.js HTTP/1.1\u001b[0m\" 304 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:16] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:22] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:28] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:34] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:40] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:46] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:52] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:00:58] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:04] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:10] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:16] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:22] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:28] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:34] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:40] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:46] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:52] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:01:58] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:04] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:10] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:16] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:22] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:28] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:34] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:40] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:46] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:52] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:02:58] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:04] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:10] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:16] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:22] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:28] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:34] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:39] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:45] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:50] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:03:56] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:01] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:07] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:12] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:18] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:23] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:29] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:34] \"GET /get_caption HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [20/Oct/2023 01:04:40] \"GET /get_caption HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "# Import Modules\n",
        "from PIL import Image\n",
        "import os\n",
        "from flask import Flask, request, render_template, jsonify, session\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from IPython.display import Image as PyImage, display\n",
        "\n",
        "# Template folder - html/css & js files\n",
        "template = '/content/drive/MyDrive/UI_Webpage/template'\n",
        "static = '/content/drive/MyDrive/UI_Webpage/static'\n",
        "\n",
        "# Create app and run with ngrok\n",
        "app = Flask(__name__, template_folder=template, static_folder=static)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "# Create a folder to store uploaded images\n",
        "upload_folder = '/content/uploads'\n",
        "os.makedirs(upload_folder, exist_ok=True)\n",
        "\n",
        "@app.route(\"/\")\n",
        "@app.route(\"/index\")\n",
        "def index():\n",
        "  return render_template('index.html', index=True)\n",
        "\n",
        "@app.route(\"/upload_image\", methods=[\"POST\"])\n",
        "def upload_image():\n",
        "  try:\n",
        "\n",
        "    # Testing route\n",
        "    print(\"Received POST request to /upload_image\")\n",
        "    # Get the uploaded image from the request\n",
        "    uploaded_image = request.files[\"image\"]\n",
        "\n",
        "    if uploaded_image:\n",
        "      # Define path to save uplaoded image\n",
        "      image_path = os.path.join(upload_folder, \"uploaded_image.png\")\n",
        "      # Session for image_path\n",
        "      session['image_path'] = image_path\n",
        "\n",
        "      # Save the uploaded image\n",
        "      uploaded_image.save(image_path)\n",
        "\n",
        "      # Display the saved image in Colab output\n",
        "      img = PyImage(filename=image_path)\n",
        "      display(img)\n",
        "\n",
        "      return jsonify({\"message\": \"Image uploaded successfully\"})\n",
        "\n",
        "  except Exception as e:\n",
        "    return jsonify({\"message\": \"Error: \" + str(e)})\n",
        "\n",
        "@app.route(\"/get_caption\", methods=[\"GET\"])\n",
        "def get_caption():\n",
        "  try:\n",
        "\n",
        "    # Access image_path session\n",
        "    image_path = session.get('image_path', None)\n",
        "\n",
        "    if image_path:\n",
        "      print(image_path)\n",
        "      # Run through image captioner\n",
        "      final_output = image_captioning(image_path)\n",
        "\n",
        "      # Print Output\n",
        "      print(\"final output: \" + final_output.rstrip())\n",
        "\n",
        "      return jsonify({\"caption\": final_output.rstrip()})\n",
        "    else:\n",
        "      return jsonify({\"message\": \"Image path not found\"})\n",
        "\n",
        "  # Testing - Static Output\n",
        "  # final_output = \"This is a sample caption generated\"\n",
        "  except Exception as e:\n",
        "    return jsonify({\"message\": \"Error: \" + str(e)})\n",
        "\n",
        "# Enable sessions\n",
        "app.secret_key = 'user_secret_key'\n",
        "\n",
        "app.run()"
      ],
      "id": "HkHx2xSmli5d"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}